{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d8ccd4-60fa-49fa-a1a8-204d3d87747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87828313-57e7-43ff-81e9-47049735de32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PhysicalDevice</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/physical_device:GPU:0'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'GPU'</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mPhysicalDevice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'/physical_device:GPU:0'\u001b[0m, \u001b[33mdevice_type\u001b[0m=\u001b[32m'GPU'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2, os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from typing import Tuple, List, Union, Optional\n",
    "\n",
    "from rich import pretty\n",
    "from rich.console import Console\n",
    "from rich.traceback import install\n",
    "from rich.progress import Progress\n",
    "from rich import inspect\n",
    "\n",
    "from models.MobileNetDecoder import MobileNetDecoder\n",
    "from utils.image_handler import *\n",
    "\n",
    "console = Console()\n",
    "pretty.install()\n",
    "install() # install rich traceback\n",
    "print = console.print\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb1f978c-66b9-4433-8c18-d67a1095d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "INPUT_SHAPE = (128, 128, 3)\n",
    "EPOCHS = 100\n",
    "SAVE_PERIOD = 10\n",
    "LR = 1e-3,\n",
    "GAMMA = .7 #scheduler decay rate\n",
    "DATA_PATH = 'datasets/subflickr/'\n",
    "MODEL_SAVE_PATH = 'saved_models/weights/'\n",
    "LOG_PATH = 'runs/MOBILENET_DECODER_100EP_1'\n",
    "\n",
    "data_gen_args = dict(\n",
    "    brightness_range=[0.5, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    rescale=1/255,\n",
    "    fill_mode='reflect',\n",
    "    data_format='channels_last'\n",
    ")\n",
    "data_flow_args = dict(\n",
    "    target_size=INPUT_SHAPE[:-1],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='input') # Since we want to reconstruct the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c7b9d1a-16d6-4ae0-9acd-a159f1d3c5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3520 images belonging to 1 classes.\n",
      "Found 880 images belonging to 1 classes.\n",
      "Found 1100 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "val_datagen = ImageDataGenerator(**data_gen_args)\n",
    "test_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(\n",
    "    os.path.join(os.path.abspath(DATA_PATH), 'train'),\n",
    "    **data_flow_args)\n",
    "\n",
    "val_batches = val_datagen.flow_from_directory(\n",
    "    os.path.join(os.path.abspath(DATA_PATH), 'val'),\n",
    "    **data_flow_args)\n",
    "\n",
    "test_batches = val_datagen.flow_from_directory(\n",
    "    os.path.join(os.path.abspath(DATA_PATH), 'test'),\n",
    "    **data_flow_args)\n",
    "\n",
    "train_gen_batches = generator(train_batches, noise_sd=0)\n",
    "val_gen_batches = generator(val_batches, noise_sd=0)\n",
    "test_gen_batches = generator(test_batches, noise_sd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3cadd4-26a2-4e46-ab1f-96b2001c03ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobile_net_decoder_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Sequential)         (None, 5120)              2257984   \n",
      "_________________________________________________________________\n",
      "decoder (Sequential)         (None, 128, 128, 3)       3048476   \n",
      "=================================================================\n",
      "Total params: 5,306,460\n",
      "Trainable params: 5,272,100\n",
      "Non-trainable params: 34,360\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_128 (Functi (None, 4, 4, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 1280)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5120)              0         \n",
      "=================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 2, 2, 1280)        0         \n",
      "_________________________________________________________________\n",
      "subpixel_1 (Subpixel)        (None, 4, 4, 64)          2949376   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d (SpatialDr (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "subpixel_2 (Subpixel)        (None, 8, 8, 32)          73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_1 (Spatial (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "subpixel_3 (Subpixel)        (None, 16, 16, 16)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_2 (Spatial (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "subpixel_4 (Subpixel)        (None, 32, 32, 8)         4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_3 (Spatial (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "subpixel_5 (Subpixel)        (None, 64, 64, 4)         1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 4)         16        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 64, 4)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_4 (Spatial (None, 64, 64, 4)         0         \n",
      "_________________________________________________________________\n",
      "subpixel_6 (Subpixel)        (None, 128, 128, 3)       444       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 3,048,476\n",
      "Trainable params: 3,048,228\n",
      "Non-trainable params: 248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetDecoder(\n",
    "    shape=INPUT_SHAPE,\n",
    "    dropout=.2\n",
    ")\n",
    "model.build((None, *INPUT_SHAPE))\n",
    "model.summary()\n",
    "model.encode_decode_summary()\n",
    "#scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#    LR,\n",
    "#    decay_steps=len(train_batches),\n",
    "#    decay_rate=GAMMA)\n",
    "#model.compile(optimizer=Adam(scheduler), loss='mse', metrics=['accuracy'])\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab98f9a5-2de7-4319-b5bd-7669d53795ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "saved_weight = os.path.join(MODEL_SAVE_PATH, 'weights.{epoch:02d}-{val_accuracy:.2f}.hdf5')\n",
    "modelchk = tf.keras.callbacks.ModelCheckpoint(saved_weight, \n",
    "                                      monitor='val_accuracy', \n",
    "                                      verbose=1,\n",
    "                                      save_best_only=True, \n",
    "                                      save_weights_only=False,\n",
    "                                      mode='auto',\n",
    "                                      save_freq='epoch') # save models every epoch\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=LOG_PATH,\n",
    "                                          histogram_freq=0,\n",
    "                                          write_graph=True,\n",
    "                                          write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1d777-f83a-497a-b23f-b2371af35e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "220/220 [==============================] - 86s 164ms/step - loss: 0.0700 - accuracy: 0.3350 - val_loss: 0.0814 - val_accuracy: 0.3718\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.37180, saving model to saved_models/weights/weights.01-0.37.hdf5\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 34s 155ms/step - loss: 0.0456 - accuracy: 0.4002 - val_loss: 0.0784 - val_accuracy: 0.3747\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.37180 to 0.37468, saving model to saved_models/weights/weights.02-0.37.hdf5\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 34s 156ms/step - loss: 0.0431 - accuracy: 0.4135 - val_loss: 0.0710 - val_accuracy: 0.3786\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.37468 to 0.37858, saving model to saved_models/weights/weights.03-0.38.hdf5\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 34s 155ms/step - loss: 0.0403 - accuracy: 0.4339 - val_loss: 0.0568 - val_accuracy: 0.3872\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.37858 to 0.38718, saving model to saved_models/weights/weights.04-0.39.hdf5\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 34s 155ms/step - loss: 0.0411 - accuracy: 0.4183 - val_loss: 0.0593 - val_accuracy: 0.3876\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.38718 to 0.38762, saving model to saved_models/weights/weights.05-0.39.hdf5\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 34s 156ms/step - loss: 0.0399 - accuracy: 0.4255 - val_loss: 0.0517 - val_accuracy: 0.3734\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.38762\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 34s 157ms/step - loss: 0.0386 - accuracy: 0.4116 - val_loss: 0.0549 - val_accuracy: 0.3657\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.38762\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 34s 156ms/step - loss: 0.0387 - accuracy: 0.4123 - val_loss: 0.0524 - val_accuracy: 0.3590\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.38762\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 34s 156ms/step - loss: 0.0383 - accuracy: 0.4019 - val_loss: 0.0515 - val_accuracy: 0.3605\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.38762\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 34s 156ms/step - loss: 0.0386 - accuracy: 0.4069 - val_loss: 0.0507 - val_accuracy: 0.3704\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.38762\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 34s 157ms/step - loss: 0.0378 - accuracy: 0.4075 - val_loss: 0.0489 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.38762\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 34s 156ms/step - loss: 0.0374 - accuracy: 0.4065 - val_loss: 0.0559 - val_accuracy: 0.3974\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.38762 to 0.39744, saving model to saved_models/weights/weights.12-0.40.hdf5\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 34s 156ms/step - loss: 0.0382 - accuracy: 0.4034 - val_loss: 0.0517 - val_accuracy: 0.3778\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.39744\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 34s 157ms/step - loss: 0.0368 - accuracy: 0.4061 - val_loss: 0.0522 - val_accuracy: 0.3916\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.39744\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 34s 156ms/step - loss: 0.0370 - accuracy: 0.4116 - val_loss: 0.0480 - val_accuracy: 0.3776\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.39744\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 34s 157ms/step - loss: 0.0365 - accuracy: 0.4058 - val_loss: 0.0509 - val_accuracy: 0.3887\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.39744\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 35s 158ms/step - loss: 0.0364 - accuracy: 0.4040 - val_loss: 0.0465 - val_accuracy: 0.3832\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.39744\n",
      "Epoch 18/100\n",
      "176/220 [=======================>......] - ETA: 3s - loss: 0.0368 - accuracy: 0.3971"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_gen_batches,\n",
    "            steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            verbose=1, \n",
    "            validation_data=val_gen_batches,\n",
    "            validation_steps = train_batches.samples // BATCH_SIZE,\n",
    "            callbacks=[modelchk, tensorboard],\n",
    "            use_multiprocessing=False).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06909a-9694-4f12-98a5-6cfc523fe0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
